# 하둡 프로그래밍

#### 데이터 종류

* 정형 데이터
  * 필드 고정
  * text 형식의 데이터
* 반정형 데이터
  * 필드 고정 X
  * XML, JSON
* 비정형 데이터
  * 다양한 데이터(사진, 동영상, 메신저, 위치정보)



#### SQL vs NoSQL

* SQL
  * 기존의 RDBMS
  * mysql, oracle ...
* NoSQL
  * 비정형데이터를 처리하기 위한 기술
  * 관계보다는 키와 값으로 단순 처리
  * 조인 X, 샤딩 활용
  * mongoDB, Hbase, aws DynamoDB



####  데이터 저장 기법

* DAS(Direct Attached Storage)
  * 서버에 직접 저장장치 추가
  * 속도 good, 연결 한계
* NAS(Network Attached Storage)
  * 네트워크를 통해 연결
  * 확장성과 유연성 좋음, but 속도 별로
* SAM(Storage-Area Network)
  * 광케이블로 고속처리 가능(Fiber Channel Switch)



#### Sharding

- RDB에서 대량의 데이터를 처리하기 위해 데이터를 파티셔닝 하는 기술
- ex) 15만명의 회원 데이터를 성씨로 파티셔닝



#### SSH vs Telnet

* 보안통신 / 평문기반 통신



---



## 설치 전에...

#### 설치 목록

* VMware (virtual machine)
* Xshell (SSH 접속)
* 우분투 (Linux)



#### IP 관련 설정

* VMware-edit-virtual network edit : 전체 ip 대역 잡아줘서 내, 외부로 통신 가능케 함 (192.168.100.0)

  * 1은 컴퓨터, 2는 VM

  * 사용 가능한건 3~254까지

* ubuntu : 각 서버한테 IP 주소를 줌 (192.168.100.10, ...)



#### VM 종료 시

* Master 우클릭 - Power - Shut Down Guest
* 절대 그냥 닫아버리지 않기 (본체의 코드를 그냥 뽑아버리는 것과 동일)



---



## Hadoop 싱글모드 구축

#### net-tools, vim, ssh, Jdk 설치 및 환경변수 설정

`sudo apt-get update`

`sudo apt install net-tools`

`sudo apt-get install vim -y`

`sudo apt-get install ssh -y`

`ifconfig` // net-tools 확인

`vim ` // vim 확인

`sudo /etc/init.d/ssh start` // ssh 확인

`sudo apt-get install default-jdk -y` // jdk 설치

`java -version`

`readlink -f /usr/bin/java` // 자바 위치

`sudo vim /etc/profile` // 아래 코드 추가

```
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
```



#### hadoop 설치 및 설정

`wget http://apache.tt.co.kr/hadoop/common/hadoop-2.9.2/hadoop-2.9.2.tar.gz` // 하둡 설치

`tar -xzvf hadoop-2.9.2.tar.gz`

`sudo mkdir -p /usr/local/hadoop`

`ls /usr/local`

`cd hadoop-2.9.2`

`sudo mv * /usr/local/hadoop`

`cd ..`

`rm -r hadoop-2.9.2`



`sudo addgroup hadoop`

`sudo adduser --ingroup hadoop manager`

`groups manager #manager : hadoop`

`sudo adduser manager sudo` // 관리자 권한으로 상승, manager 라는 애가 hadoop을 관리하는 애가 됨

`groups manager` // manager : hadoop sudo

`sudo chown -R manager:hadoop /usr/local/hadoop/` // 소유자에게 소유그룹 지정

`ls -l /usr/local/hadoop` // manager hadoop 확인

`su - manager` // -가 붙으면 manager의 홈 디렉토리로 로그인

`ls -a` // -a는 숨김파일도 보여줌

`sudo vim .bashrc` // .bashrc에 아래 코드 추가

```linux
#HADOOP VARIABLES START
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
#HADOOP VARIABLES END
```

`source .bashrc` // .bashrc 변경 적용

`$HADOOP_HOME` // 변수 지정 확인

VM - Snapshot - Take Snapshot - 하둡 설치 완료

( 추후에 잘못 설정했을 때 현 상태로 되돌릴 수 있음)



#### Xshell로 이동하여 작업

* 새 세션 등록
  * 이름 : master
  * host : 192.168.100.10
  * manager로 로그인

`sudo vim /usr/local/hadoop/etc/hadoop/hadoop-env.sh`

```
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 // 25번째 줄
```

`sudo mkdir -p /usr/local/hadoop/tmp`

`sudo chown -R manager:hadoop /usr/local/hadoop/tmp`

`sudo vim /usr/local/hadoop/etc/hadoop/core-site.xml` // 62530 포트번호는 내맘대로

```
<configuration>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/usr/local/hadoop/tmp</value>
	</property>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://localhost:62350</value>
	</property>
</configuration>
```

`sudo mkdir -p /usr/local/hadoop/hdfs/namenode`

`sudo mkdir -p /usr/local/hadoop/hdfs/datanode`

`sudo chown -R manager:hadoop /usr/local/hadoop/` // 권한 변경(하위까지)

`sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml` // 아래코드 추가

```
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/usr/local/hadoop/hdfs/namenode</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/usr/local/hadoop/hdfs/datanode</value>
	</property>
</configuration>
```

`ssh-keygen -t rsa` // 인증키 받기

`ssh-copy-id -i .ssh/id_rsa.pub manager@localhost` // manage 계정에 ssh키 copy

`hadoop namenode -format` // namenode 초기화

`start-dfs.sh` // dfs실행

`jps` // 하둡에서 실행되는 프로세서 보여줌, 아래 4가지가 떠야함

```
datanode
namenode
secondarynamenode
jps
```



* 안될 시
  * namenode, datanode 안의 내용 삭제 후 format



* Filezilla 설치
  * 192.168.100.10:22 / manager / 1 로 연결
  * 배포파일 - 싱글 모드 테스트의 두가지 파일 업로드 (CHANGES.txt, WordCount.jar)



#### WordCount Test

// input data 파일과 jar 파일 넣을 폴더 생성 및 mv

`sudo mkdir -p /usr/local/hadoop/data`

`sudo mkdir -p /usr/local/hadoop/jar`

`sudo chown -R manager:hadoop /usr/local/hadoop/`

`sudo mv CHANGES.txt /usr/local/hadoop/data/`

`sudo mv WordCount.jar /usr/local/hadoop/jar/`



// hadoop 실행

`hadoop fs -mkdir -p /wordcount/input`

`hadoop fs -ls /wordcount` // 폴더 생성 확인

`hadoop fs -copyFromLocal /usr/local/hadoop/data/* /wordcount/input`

`hadoop fs -ls /wordcount/input` // 파일 copy 확인

`hadoop jar /usr/local/hadoop/jar/WordCount.jar com.care.WordCount.WordCount /wordcount/input /wordcount/output` // WordCount.jar 실행

`hadoop fs -cat /wordcount/output/part-00000` // 결과 출력



---



## Hadoop 멀티모드 구축

* Slave 생성
  * File - Export to OVF... // Master 배포
  * File - Open - 이름과 경로 지정 - Import // Slave 생성
  * network 맞춰주고 Take snapshot
  * slave들은 Memory 1GB로 변경 (자신의 컴퓨터 성능에 따라 선택)



#### 각 서버 계정 명 변경

`sudo vim /etc/hostname`

`dd`(삭제) 후 각 이름 변경

`sudo /bin/hostname -F /etc/hostname` // 적용

`sudo reboot` // reboot 한 후 각 계정 이름 바뀐거 확인



#### Master에서 실행

`stop-dfs.sh`

`rm -rf /usr/local/hadoop/hdfs/datanode` // Slave 서버가 datanode 역할

`ls /usr/local/hadoop/hdfs/namenode`

`rm -rf /usr/local/hadoop/hdfs/namenode/*`

`sudo vim /etc/hosts` // 4개 서버 모두 적용

```
192.168.100.10  master
192.168.100.20  slave1
192.168.100.30  slave2
192.168.100.40  slave3
```



// slaves 설정 (모든 서버 적용)

`sudo vim /usr/local/hadoop/etc/hadoop/slaves // 아래 코드로 변경

```
slave1
slave2
slave3
```



// Master에서 노드 변경

`sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml` // 아래 코드로 변경(Master만)

```
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/usr/local/hadoop/hdfs/namenode</value>
	</property>
	<property>
		<name>dfs.http.address</name>
		<value>master:50070</value>
	</property>
	<property>
		<name>dfs.secondary.http.address</name>
		<value>slave1:50090</value>
	</property>
</configuration>
```



`sudo vim /usr/local/hadoop/etc/hadoop/mapred-site.xml` // 아래 코드로 변경(4개 서버 모두)

```
<configuration>
	<property>
		<name>mapred.job.tracker</name>
		<value>master:62351</value>
	</property>
</configuration>
```

`sudo vim /usr/local/hadoop/etc/hadoop/core-site.xml` // 아래 코드로 변경(4개 서버 모두)

```
<configuration>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/usr/local/hadoop/tmp</value>
	</property>
	<property>
		<name>fs.default.name</name>
		<value>hdfs://master:62350</value>
	</property>
</configuration>
```



// 인증키 생성 및 배포 (master에서 실행)

`ssh-keygen -t rsa`

`ssh-copy-id -i .ssh/id_rsa.pub manager@master`

`ssh-copy-id -i .ssh/id_rsa.pub manager@slave1`

`ssh-copy-id -i .ssh/id_rsa.pub manager@slave2`

`ssh-copy-id -i .ssh/id_rsa.pub manager@slave3`



// Slave에서 실행 (들어오는 내용을 저장만 하면 되는 서버들. datanode)

`sudo vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml`

// 아래 코드로 변경 <configuration> 아래서 8dd

```
<configuration>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/hadoop/hdfs/datanode</value>
        </property>
</configuration>
```

`sudo rm -rf /usr/local/hadoop/hdfs/namenode`

`sudo rm -rf /usr/local/hadoop/hdfs/datanode/*`



// Master에서 hadoop 실행

`hadoop namenode -format`

`start-all.sh` // 4개 서버가 모두 돌아야 함

`jps` // 아래처럼 나와야함

```
master : NameNode, Jps, ResourceManager
slave1 : NodeManager, DataNode, Jps, SecondaryNameNode
slave2 : Jps, NodeManager, DataNode
slave3 : Jps, NodeManager, DataNode
```



#### Web (192.168.100.10:50070)

* Livenode : 3 확인



---



## WordCount 코딩 및 실행

#### eclipse

1. java project 생성 (name : WordCount)
2. 프로젝트 protperties - Java Build Path - Libraries - Add External JARs....
3. hadoop API 3가지 추가
   - /usr/local/hadoop/share/hadoop/common/hadoop-common-2.9.2.jar
   - /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.9.2.jar
   - /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.9.2.jar
4. 코딩 .... (WordCount 프로젝트 참고)
5. jar 파일 생성
6. filezilla로 /home/manager 에 jar 파일 업로드



#### WordCount Test

// 기존 파일 삭제하고 새로 생성한 WordCount.jar 파일 옮기기

`sudo rm -rf /usr/local/hadoop/jar/WordCount.jar`

`sudo mv WordCount.jar /usr/local/hadoop/jar/` // 옮기지 않고 그냥 바로 실행해도 됨



// hadoop 실행

`hadoop fs -mkdir -p /wordcount/input`

`hadoop fs -ls /wordcount` // 폴더 생성 확인

`hadoop fs -copyFromLocal /usr/local/hadoop/data/* /wordcount/input`

`hadoop fs -ls /wordcount/input` // 파일 copy 확인

`hadoop jar /usr/local/hadoop/jar/WordCount.jar WordCount /wordcount/input /wordcount/output` // WordCount.jar 실행

`hadoop fs -cat /wordcount/output/part-00000` // 결과 출력



#### safemode 걸렸을 때 오류 해결

`hadoop dfsadmin -safemode leave` 또는 `sudo reboot`



---



## 항공 데이터

`hadoop fs -mkdir /airdata`



`head 2008.csv > 2008_head.csv`

`sed -e '1d' 2008.csv > 2008_sub.csv` // 상위 1줄(컬럼) 삭제

`head 2008_sub.csv > 2008_head.csv` // 일부만 저장(10개)

`hadoop fs -put 2008_head.csv /airdata`



// 연도별로 sub.csv 파일 생성 후 hadoop에 복사

`sed -e '1d' 2005.csv > 2005_sub.csv`

`sed -e '1d' 2006.csv > 2006_sub.csv`

`sed -e '1d' 2007.csv > 2007_sub.csv`

`hadoop fs -mkdir /air`

`hadoop fs -copyFromLocal 2005_sub.csv /air`

`hadoop fs -copyFromLocal 2006_sub.csv /air`

`hadoop fs -copyFromLocal 2007_sub.csv /air`



#### 알아둘 것

* map에서 reduce로 넘겨줄 때의 key 값으로 정렬 출력
